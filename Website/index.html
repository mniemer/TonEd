<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>TonEd: EECS 352 WQ 2017</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="index.html">TonEd</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-left">
                    <li>
                        <a href="#About">About</a>
                    </li>
                    <li>
                        <a href="#Problem">Problem</a>
                    </li>
                    <li>
                        <a href="#Solution">Solution</a>
                    </li>
                    <li>
                        <a href="#Results">Results</a>
                    </li>
                    <li>
                        <a href="#FutureWork">Future Work</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>
    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/violin.jpg')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="site-heading">
                        <h1>TonEd</h1>
                        <hr class="small">
                        <span class="subheading">Matthew Niemer, Christopher Pierce</span>
                        <span class="subheading">Contact Email: matthewniemer2018@u.northwestern.edu</span>
                        <span class="subheading">EECS 352 Northwestern University, Prof. Bryan Pardo</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content -->
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-preview">
                    <h2 class="post-title" id="About">
                        What is TonEd?
                    </h2>
                    <p> TonEd is a tool that can be used to identify different kinds of violin tone and diagnose the underlying cause of poor tone quality. Young violin students often struggle to play with a rich, full tone - TonEd aims to be useful for students who wish to improve their tone but may not have access to a trained instructor who would be able to identify the problems influencing the tone of their notes. TonEd is partially inspired by existing commercial music education programs, most notably <a href="http://smartmusic.com">SmartMusic</a>, which allow students to record themselves practicing and then give feedback on intonation, tempo, and other stylistic elements. However, these programs fail to identify tone deficiencies well, which is the specific niche our project fills. </p>
                </div>
                <hr>
                 <div class="post-preview">
                    <h2 class="post-title" id="Problem">
                        Problem

                    </h2>
                    <p> The problem is simple. Young violinists want to play with a full, rich, and beautiful tone:
                    <br>
                    <audio controls>
                    <source src = "../samples/MeganRenner_Full.wav" type = "audio/wav">
                    </audio>
                    <br>
                    But instead, their tone is crunchy and unpleasant:
                    <br>
                    <audio controls>
                    <source src = "../samples/JonHuang_Crunchy.wav" type = "audio/wav">
                    </audio>
                    <br>
                    Or too thin and covered:
                    <br>
                    <audio controls>
                    <source src = "../samples/JonHuang_Thin.wav" type = "audio/wav">
                    </audio>
                    <br>
                    A young violin student has two problems when it comes to tone. The first is that their ears are not trained to reliably tell what a full, rich tone sounds like. The second is that once the student realizes they are playing with poor tone, they are unable to quickly diagnose the cause behind their poor tone. A good teacher solves both of these problems, but TonEd aims to help students who may not have access to quality instruction.
                    </p>
                </div>
                <hr>
                <div class="post-preview">
                    <h2 class="post-title" id="Solution">
                        Solution
                    </h2>
                    <p> Our solution is a simple nearest neighbor classifier. Given an input recording of a scale played on a violin, the recording's tone is classified as one of three discrete categories: Full, Thin, or Crunchy. Using this feedback the student can then improve the quality of their music after having identified the errors causing them to play with poor tone. 
                    <img src='img/flowchart.png' style='width: 100%; height: auto'>
                    </p>
                    <p>
                    The classifier is trained on a set of recordings from six experienced violinists with good tone control, who each provided a crunchy, thin, and full toned sample. Our sample collection guide is available <a href="TonEdSampleCollection.pdf">here</a>. Each sample consists of a 2 octave C Major scale played at 100 beats per minute. Each of these recordings is broken down on a note by note basis, and subsequently the Mel Frequency Cepstral Coefficents (MFCCs) of each of these notes is calculated and used to train the nearest neighbor classifier. Each recording contains 29 notes, thus the model is trained on 522 total data points. We used several different testing methods to measure the success of our classifier, including leave one out cross validation and ten fold cross validation. We measured the success of our classifier using the precision value of the results, and we used a confusion matrix as well to analyze classification results.
                    </p>
                    <p>
                    A practical use of TonEd means classifying whole scales together in one piece. We do this by breaking down the scale into notes and then classifying each note as either Full, Thin, or Crunchy. We then simply identify the most common class of the notes that made up the scale and assign the whole scale that class.
                    </p>
                    <h4>
                    Feature Extraction
                    </h4>
                    <p>
                    Our feature extraction begins with the MFCC of an entire scale.
                    <img src='img/MFCC.png' style='width: 100%; height: auto'>
                    In order to provide more data for our machine learning algorithm, we window each scale into a series of notes (29 notes per scale x 18 scales total = 522 notes). Each note has a specific tone quality associated with it. From there, we take the mean and variance of each coefficient in each note, as well the mean and variance of the first deriviative of each coefficient in each note and save these features in a one dimensional array.
                    <img src='img/full_features.png' style='width: 100%; height: auto'>
                    <img src='img/thin_features.png' style='width: 100%; height: auto'>
                    <img src='img/crunchy_features.png' style='width: 100%; height: auto'>
                    We train our machine learning algorithm on the set features extracted from our set of 522 notes.
                    </p>
                    <h4>
                    Choosing an Algorithm
                    </h4>
                    <p>
                    After feature extraction, we used the vectors to train various different machine learning algorithms, including Decision Trees, Nearest Neighbor, Multi-Layer Perceptrons, and Stochastic Gradient Descent. We used cross validation techniques to judge the performance of each algorithm on our data set, and Nearest Neighbor performed the best, with a precision of .52. On certain scales in our data set other algorithms perform better than Nearest Neighbor, but we found that overall it has the highest performance statistics of the algorithms we tested and thus is best suited to the general case of an unknown input scale. 
                    </p>

                </div>
                <hr>
                <div class="post-preview">
                    <h2 class="post-title" id="Results">
                        Results
                    </h2>
                    <p> Our results are fair but certainly not ready for widespread use. Given the difficult nature of our task, however, we feel that our results show promising signs for future development. The chart below outlines our success with 10 fold cross validation tests with different sets of features and different machine learning algorithms.
                    <img src='img/results.png' style='width: 100%; height: auto'>
                    Our cross validation tests give the best results when we use the Nearest Neighbor algorithm and include all of our features, achieving a success rate of about 52%. This is significantly better than guessing, which would yield a rate of about 33%. However, we believe that even better results can be achieved with more work and research.
                    <br>
                    Classifying scales yields similar results. We tested our scale classification by holding out a single person's samples from the training set and then classifying each of that person's 3 scales. As we would expect, our scale classification generally reports the correct scale about 60% of the time.
                    </p>
                </div>
                <hr>
                <div class="post-preview">
                    <h2 class="post-title" id="FutureWork">
                        Future Work
                    </h2>
                    <p> In order to improve the performance of our system there are two main areas we believe can be improved: feature extraction and fine-tuning the algorithm we use. In order to improve feature extraction, further research into the similarities and differences between the timbre of individual violins would allow us to use features that identify the thin, crunchy or full tone of a recording rather than the characteristics of the violin used to create the recording. Fine tuning the learning algorithms that we use would also help improve the performance of our system, because we were able to achieve drastically different precision depending on the parameters used for the algorithms. The parameters we selected were the best that we found, however we believe that extensive further testing could help isolate the best input parameters for each algorithm, which would increase the precision of our system. 
                    </p>
                </div>
                <hr>

            </div>
        </div>
    </div>

    <hr>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

</body>

</html>
